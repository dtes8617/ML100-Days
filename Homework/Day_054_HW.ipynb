{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 作業\n",
    "* 試著想想看, 非監督學習是否有可能使用評價函數 (Metric) 來鑑別好壞呢?  \n",
    "(Hint : 可以分為 \"有目標值\" 與 \"無目標值\" 兩個方向思考)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "針對有目標的問題，基本上如果有明確 Label ，是可以用 supervised 的演算法來解決的。如果要採用 unsupervised 的方式，就可以直接拿 Label 來比較分類的差異。這時就有 Confusion Metrics 的相關指標可以參考。另外，對與指標不那麼明確，譬如說想要買某樣商品卻沒有相對應的 Label 可以參考時，也可以實驗/對照組來比對是否有差異，但這樣的方式反應模型效能的時間較長，通常較不適合。\n",
    "\n",
    "針對無目標值的問題，可以用組內/組間的差異來評估分類模型的好壞。這樣的基本想法主要架構在，如果資料是同一類型，理想狀況是他的各個屬性應該要一定程度的相似。因此如果被歸類同一群體，彼此差異不能太大，但組跟組間的差異則盡量拉大，藉此保證分類的效果。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
