{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work\n",
    "1. 請比較使用 l1, l1_l2 及不同比例下的訓練結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import keras\n",
    "\n",
    "# Disable GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 資料前處理\n",
    "def preproc_x(x, flatten=True):\n",
    "    x = x / 255.\n",
    "    if flatten:\n",
    "        x = x.reshape((len(x), -1))\n",
    "    return x\n",
    "\n",
    "def preproc_y(y, num_classes=10):\n",
    "    if y.shape[-1] == 1:\n",
    "        y = keras.utils.to_categorical(y, num_classes)\n",
    "    return y    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = train\n",
    "x_test, y_test = test\n",
    "\n",
    "# Preproc the inputs\n",
    "x_train = preproc_x(x_train)\n",
    "x_test = preproc_x(x_test)\n",
    "\n",
    "# Preprc the outputs\n",
    "y_train = preproc_y(y_train)\n",
    "y_test = preproc_y(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.regularizers import l1, l2, l1_l2\n",
    "def build_mlp(output_units=10, num_neurons=[512, 256, 128], regular= l2, ratio=1e-4):\n",
    "    \"\"\"\n",
    "    Build your own model\n",
    "    \"\"\"\n",
    "    input_layer = keras.layers.Input(x_train.shape[1:])\n",
    "    \n",
    "    for i, n_units in enumerate(num_neurons):\n",
    "        if i == 0:\n",
    "            x = keras.layers.Dense(units=n_units, \n",
    "                                   activation=\"relu\", \n",
    "                                   name=\"hidden_layer\"+str(i+1), \n",
    "                                   kernel_regularizer=regular(ratio))(input_layer)\n",
    "        else:\n",
    "            x = keras.layers.Dense(units=n_units, \n",
    "                                   activation=\"relu\", \n",
    "                                   name=\"hidden_layer\"+str(i+1),\n",
    "                                   kernel_regularizer=regular(ratio))(x)\n",
    "    \n",
    "    out = keras.layers.Dense(units=output_units, activation=\"softmax\", name=\"output\")(x)\n",
    "    \n",
    "    model = keras.models.Model(inputs=[input_layer], outputs=[out])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 超參數設定\n",
    "\"\"\"\n",
    "Set your hyper-parameters\n",
    "\"\"\"\n",
    "LEARNING_RATE = 1e-3\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 256\n",
    "MOMENTUM = 0.95\n",
    "L2_EXP = [1e-2, 1e-4, 1e-8, 1e-12]\n",
    "\n",
    "params = {'ratio':[1e-2, 1e-4, 1e-8, 1e-12],\n",
    "          'regular': [l1, l2, l1_l2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment with Regulizer = ratio_ratio, regular_regular\n",
      "WARNING:tensorflow:From C:\\Users\\Jude\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From C:\\Users\\Jude\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 7s 139us/step - loss: 198.7029 - acc: 0.2486 - val_loss: 41.1898 - val_acc: 0.2807\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 19.1624 - acc: 0.1187 - val_loss: 7.3218 - val_acc: 0.1000\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 4.1270 - acc: 0.0992 - val_loss: 2.6558 - val_acc: 0.1000\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 2.4876 - acc: 0.0985 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 2.4626 - acc: 0.0989 - val_loss: 2.4627 - val_acc: 0.1000\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 2.4626 - acc: 0.0971 - val_loss: 2.4627 - val_acc: 0.1000\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 2.4626 - acc: 0.0978 - val_loss: 2.4627 - val_acc: 0.1000\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 2.4626 - acc: 0.0978 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 2.4626 - acc: 0.0997 - val_loss: 2.4627 - val_acc: 0.1000\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 2.4626 - acc: 0.0989 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 2.4626 - acc: 0.0984 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 2.4626 - acc: 0.0991 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 2.4626 - acc: 0.0973 - val_loss: 2.4627 - val_acc: 0.1000\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 2.4626 - acc: 0.0978 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 2.4626 - acc: 0.0979 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 2.4626 - acc: 0.0981 - val_loss: 2.4627 - val_acc: 0.1000\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 2.4626 - acc: 0.0971 - val_loss: 2.4627 - val_acc: 0.1000\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 2.4626 - acc: 0.0968 - val_loss: 2.4628 - val_acc: 0.1000\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 2.4626 - acc: 0.0990 - val_loss: 2.4627 - val_acc: 0.1000\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 2.4626 - acc: 0.0988 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 2.4626 - acc: 0.0989 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 3s 61us/step - loss: 2.4626 - acc: 0.0987 - val_loss: 2.4627 - val_acc: 0.1000\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 2.4626 - acc: 0.0978 - val_loss: 2.4627 - val_acc: 0.1000\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 2.4626 - acc: 0.0981 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 2.4626 - acc: 0.0979 - val_loss: 2.4627 - val_acc: 0.1000\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 2.4626 - acc: 0.0962 - val_loss: 2.4627 - val_acc: 0.1000\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 2.4626 - acc: 0.0964 - val_loss: 2.4627 - val_acc: 0.1000\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 2.4626 - acc: 0.0969 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 2.4626 - acc: 0.0969 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 2.4626 - acc: 0.0981 - val_loss: 2.4627 - val_acc: 0.1000\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 2.4626 - acc: 0.0961 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 2.4626 - acc: 0.0966 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 2.4626 - acc: 0.0976 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 2.4626 - acc: 0.0966 - val_loss: 2.4627 - val_acc: 0.1000\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 2.4626 - acc: 0.0970 - val_loss: 2.4627 - val_acc: 0.1000\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 2.4626 - acc: 0.0987 - val_loss: 2.4627 - val_acc: 0.10000s - loss: 2.4626 - acc: 0.\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 2.4626 - acc: 0.0971 - val_loss: 2.4627 - val_acc: 0.1000\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 2.4626 - acc: 0.0976 - val_loss: 2.4627 - val_acc: 0.1000\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 2.4626 - acc: 0.0979 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 2.4626 - acc: 0.0996 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 2.4626 - acc: 0.0961 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 2.4626 - acc: 0.0980 - val_loss: 2.4627 - val_acc: 0.1000\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 2.4626 - acc: 0.0986 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 2.4626 - acc: 0.0980 - val_loss: 2.4627 - val_acc: 0.1000\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 2.4626 - acc: 0.0971 - val_loss: 2.4627 - val_acc: 0.1000\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 2.4626 - acc: 0.0982 - val_loss: 2.4627 - val_acc: 0.1000\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 2.4626 - acc: 0.0972 - val_loss: 2.4627 - val_acc: 0.1000\n",
      "Epoch 48/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 3s 52us/step - loss: 2.4626 - acc: 0.0971 - val_loss: 2.4626 - val_acc: 0.1000\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 2.4626 - acc: 0.0983 - val_loss: 2.4627 - val_acc: 0.1000\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 2.4626 - acc: 0.0972 - val_loss: 2.4627 - val_acc: 0.1000\n",
      "Experiment with Regulizer = ratio_ratio, regular_regular\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 3s 67us/step - loss: 15.0585 - acc: 0.2727 - val_loss: 13.9316 - val_acc: 0.3353\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 13.0035 - acc: 0.3549 - val_loss: 12.1169 - val_acc: 0.3654\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 11.3329 - acc: 0.3796 - val_loss: 10.5787 - val_acc: 0.3950\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 3s 63us/step - loss: 9.9201 - acc: 0.3955 - val_loss: 9.2870 - val_acc: 0.4007\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 8.7217 - acc: 0.4067 - val_loss: 8.1737 - val_acc: 0.4186\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 7.7001 - acc: 0.4149 - val_loss: 7.2440 - val_acc: 0.4174\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 6.8280 - acc: 0.4225 - val_loss: 6.4377 - val_acc: 0.4296\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 6.0846 - acc: 0.4284 - val_loss: 5.7547 - val_acc: 0.4312\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 5.4507 - acc: 0.4338 - val_loss: 5.1671 - val_acc: 0.4361\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 4.9071 - acc: 0.4407 - val_loss: 4.6775 - val_acc: 0.4332\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 4.4434 - acc: 0.4425 - val_loss: 4.2420 - val_acc: 0.4401\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 4.0443 - acc: 0.4476 - val_loss: 3.8672 - val_acc: 0.4516\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 3.7036 - acc: 0.4522 - val_loss: 3.5634 - val_acc: 0.4423\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 3.4133 - acc: 0.4557 - val_loss: 3.2942 - val_acc: 0.4500\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 3.1642 - acc: 0.4577 - val_loss: 3.0632 - val_acc: 0.4528\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 2.9505 - acc: 0.4631 - val_loss: 2.8760 - val_acc: 0.4565\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 2.7673 - acc: 0.4669 - val_loss: 2.7231 - val_acc: 0.4419\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 2.6108 - acc: 0.4681 - val_loss: 2.5512 - val_acc: 0.4659\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 2.4747 - acc: 0.4717 - val_loss: 2.4509 - val_acc: 0.4579\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 2.3600 - acc: 0.4730 - val_loss: 2.3226 - val_acc: 0.4610\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 2.2599 - acc: 0.4759 - val_loss: 2.2381 - val_acc: 0.4634\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 2.1745 - acc: 0.4780 - val_loss: 2.1562 - val_acc: 0.4690\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 2.1014 - acc: 0.4803 - val_loss: 2.1083 - val_acc: 0.4656\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 2.0376 - acc: 0.4836 - val_loss: 2.0461 - val_acc: 0.4645\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.9826 - acc: 0.4850 - val_loss: 1.9847 - val_acc: 0.4755\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.9343 - acc: 0.4878 - val_loss: 1.9458 - val_acc: 0.4723\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.8934 - acc: 0.4899 - val_loss: 1.8967 - val_acc: 0.4866\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.8578 - acc: 0.4910 - val_loss: 1.9095 - val_acc: 0.4663\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.8273 - acc: 0.4934 - val_loss: 1.8706 - val_acc: 0.46971\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.8010 - acc: 0.4957 - val_loss: 1.8177 - val_acc: 0.4892\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.7758 - acc: 0.4969 - val_loss: 1.7946 - val_acc: 0.4830\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.7565 - acc: 0.4989 - val_loss: 1.7779 - val_acc: 0.4876\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.7379 - acc: 0.5012 - val_loss: 1.7776 - val_acc: 0.4820\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.7213 - acc: 0.5041 - val_loss: 1.7526 - val_acc: 0.4932\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.7080 - acc: 0.5061 - val_loss: 1.7398 - val_acc: 0.4943\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.6945 - acc: 0.5069 - val_loss: 1.7363 - val_acc: 0.4879\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.6866 - acc: 0.5057 - val_loss: 1.7529 - val_acc: 0.4803\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.6750 - acc: 0.5081 - val_loss: 1.7904 - val_acc: 0.4631\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.6660 - acc: 0.5121 - val_loss: 1.7021 - val_acc: 0.5004\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.6596 - acc: 0.5107 - val_loss: 1.7317 - val_acc: 0.4850\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.6506 - acc: 0.5131 - val_loss: 1.6984 - val_acc: 0.4968\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.6436 - acc: 0.5162 - val_loss: 1.6917 - val_acc: 0.4990\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.6413 - acc: 0.5150 - val_loss: 1.7032 - val_acc: 0.4935\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.6337 - acc: 0.5161 - val_loss: 1.7307 - val_acc: 0.4897\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.6308 - acc: 0.5194 - val_loss: 1.6938 - val_acc: 0.4892\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.6252 - acc: 0.5208 - val_loss: 1.6678 - val_acc: 0.5021\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.6206 - acc: 0.5224 - val_loss: 1.8526 - val_acc: 0.4433\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.6183 - acc: 0.5226 - val_loss: 1.6823 - val_acc: 0.4969\n",
      "Epoch 49/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 2s 50us/step - loss: 1.6142 - acc: 0.5260 - val_loss: 1.6637 - val_acc: 0.5099\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 2s 50us/step - loss: 1.6081 - acc: 0.5264 - val_loss: 1.7180 - val_acc: 0.4846\n",
      "Experiment with Regulizer = ratio_ratio, regular_regular\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 4s 71us/step - loss: 197.9427 - acc: 0.2336 - val_loss: 35.9495 - val_acc: 0.2378\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 15.9284 - acc: 0.1082 - val_loss: 5.1580 - val_acc: 0.1000\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 3.2190 - acc: 0.0990 - val_loss: 2.4716 - val_acc: 0.1000\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 2.4632 - acc: 0.0963 - val_loss: 2.4624 - val_acc: 0.1000\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 2.4624 - acc: 0.0983 - val_loss: 2.4625 - val_acc: 0.1000\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 2.4624 - acc: 0.0980 - val_loss: 2.4622 - val_acc: 0.1000\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 2.4624 - acc: 0.0965 - val_loss: 2.4622 - val_acc: 0.1000\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 2.4623 - acc: 0.0977 - val_loss: 2.4623 - val_acc: 0.1000\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 2.4623 - acc: 0.0980 - val_loss: 2.4622 - val_acc: 0.1000\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 2.4622 - acc: 0.0994 - val_loss: 2.4624 - val_acc: 0.1000\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 2.4622 - acc: 0.0996 - val_loss: 2.4620 - val_acc: 0.1000\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 2.4621 - acc: 0.0984 - val_loss: 2.4621 - val_acc: 0.1000\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 2.4621 - acc: 0.0977 - val_loss: 2.4621 - val_acc: 0.1000\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 2.4621 - acc: 0.0964 - val_loss: 2.4620 - val_acc: 0.1000\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 2.4621 - acc: 0.0979 - val_loss: 2.4620 - val_acc: 0.1000\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 2.4620 - acc: 0.0971 - val_loss: 2.4620 - val_acc: 0.1000\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 2.4620 - acc: 0.0981 - val_loss: 2.4619 - val_acc: 0.1000\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 2.4620 - acc: 0.0958 - val_loss: 2.4620 - val_acc: 0.1000\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 2.4620 - acc: 0.0985 - val_loss: 2.4619 - val_acc: 0.1000\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 2.4620 - acc: 0.0952 - val_loss: 2.4620 - val_acc: 0.1000\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 2.4620 - acc: 0.0967 - val_loss: 2.4620 - val_acc: 0.1000\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 2.4620 - acc: 0.0974 - val_loss: 2.4619 - val_acc: 0.1000\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 2.4620 - acc: 0.0963 - val_loss: 2.4619 - val_acc: 0.1000\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 2.4619 - acc: 0.0968 - val_loss: 2.4619 - val_acc: 0.1000\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 2.4619 - acc: 0.0981 - val_loss: 2.4619 - val_acc: 0.1000\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 2.4619 - acc: 0.0980 - val_loss: 2.4618 - val_acc: 0.1000\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 2.4619 - acc: 0.0974 - val_loss: 2.4618 - val_acc: 0.1000\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 2.4619 - acc: 0.0974 - val_loss: 2.4619 - val_acc: 0.1000\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 2.4619 - acc: 0.1002 - val_loss: 2.4618 - val_acc: 0.1000\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 2.4618 - acc: 0.0978 - val_loss: 2.4618 - val_acc: 0.1000\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 2.4618 - acc: 0.0984 - val_loss: 2.4617 - val_acc: 0.1000\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 2.4618 - acc: 0.0987 - val_loss: 2.4618 - val_acc: 0.1000\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 2.4618 - acc: 0.0974 - val_loss: 2.4617 - val_acc: 0.1000\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 2.4618 - acc: 0.1000 - val_loss: 2.4617 - val_acc: 0.1000\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 2.4617 - acc: 0.0966 - val_loss: 2.4617 - val_acc: 0.1000\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 2.4617 - acc: 0.0992 - val_loss: 2.4616 - val_acc: 0.1000\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 2.4617 - acc: 0.0957 - val_loss: 2.4617 - val_acc: 0.1000\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 2.4617 - acc: 0.0985 - val_loss: 2.4616 - val_acc: 0.1000\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 2.4616 - acc: 0.0971 - val_loss: 2.4616 - val_acc: 0.1000\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 2.4616 - acc: 0.0977 - val_loss: 2.4616 - val_acc: 0.1000\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 2.4616 - acc: 0.0977 - val_loss: 2.4615 - val_acc: 0.1000\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 2.4616 - acc: 0.0970 - val_loss: 2.4615 - val_acc: 0.1000\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 2.4615 - acc: 0.0967 - val_loss: 2.4615 - val_acc: 0.1000\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 2.4615 - acc: 0.0990 - val_loss: 2.4614 - val_acc: 0.1000\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 2.4615 - acc: 0.0963 - val_loss: 2.4615 - val_acc: 0.1000\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 2.4615 - acc: 0.0976 - val_loss: 2.4614 - val_acc: 0.1000\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 2.4615 - acc: 0.0960 - val_loss: 2.4614 - val_acc: 0.1000\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 2.4615 - acc: 0.0982 - val_loss: 2.4614 - val_acc: 0.1000\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 2.4614 - acc: 0.0985 - val_loss: 2.4614 - val_acc: 0.1000\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 3s 53us/step - loss: 2.4614 - acc: 0.0971 - val_loss: 2.4614 - val_acc: 0.1000\n",
      "Experiment with Regulizer = ratio_ratio, regular_regular\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 3s 70us/step - loss: 6.0217 - acc: 0.2781 - val_loss: 5.8126 - val_acc: 0.3464\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 5.7263 - acc: 0.3650 - val_loss: 5.6473 - val_acc: 0.3785\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 5.5817 - acc: 0.3906 - val_loss: 5.5200 - val_acc: 0.3981\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 5.4624 - acc: 0.4118 - val_loss: 5.4060 - val_acc: 0.4207\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 5.3536 - acc: 0.4277 - val_loss: 5.3033 - val_acc: 0.4348\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 5.2546 - acc: 0.4396 - val_loss: 5.2172 - val_acc: 0.4419\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 5.1586 - acc: 0.4510 - val_loss: 5.1228 - val_acc: 0.4519\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 5.0663 - acc: 0.4630 - val_loss: 5.0472 - val_acc: 0.4546\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 4.9797 - acc: 0.4698 - val_loss: 4.9502 - val_acc: 0.4671\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 4.8934 - acc: 0.4799 - val_loss: 4.8900 - val_acc: 0.4624\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 4.8122 - acc: 0.4861 - val_loss: 4.8018 - val_acc: 0.4774\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 4.7334 - acc: 0.4933 - val_loss: 4.7323 - val_acc: 0.4787\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 4.6539 - acc: 0.5006 - val_loss: 4.6782 - val_acc: 0.4819\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 4.5787 - acc: 0.5079 - val_loss: 4.6250 - val_acc: 0.4694\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 4.5041 - acc: 0.5129 - val_loss: 4.5784 - val_acc: 0.4655\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 4.4319 - acc: 0.5180 - val_loss: 4.4568 - val_acc: 0.4968\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 4.3608 - acc: 0.5237 - val_loss: 4.4031 - val_acc: 0.4998\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 4.2903 - acc: 0.5294 - val_loss: 4.3415 - val_acc: 0.4947\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 4.2229 - acc: 0.5330 - val_loss: 4.2897 - val_acc: 0.5017\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 4.1554 - acc: 0.5392 - val_loss: 4.2301 - val_acc: 0.5005\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 4.0903 - acc: 0.5436 - val_loss: 4.1657 - val_acc: 0.5029\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 4.0262 - acc: 0.5480 - val_loss: 4.1510 - val_acc: 0.4982\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 3.9633 - acc: 0.5528 - val_loss: 4.0354 - val_acc: 0.5169\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 3.9000 - acc: 0.5565 - val_loss: 3.9880 - val_acc: 0.5173\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 3.8417 - acc: 0.5588 - val_loss: 3.9376 - val_acc: 0.5151\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 3.7822 - acc: 0.5635 - val_loss: 3.9205 - val_acc: 0.5004\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 3.7210 - acc: 0.5684 - val_loss: 3.8302 - val_acc: 0.5192\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 3.6630 - acc: 0.5717 - val_loss: 3.8053 - val_acc: 0.5129\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 3.6080 - acc: 0.5729 - val_loss: 3.7332 - val_acc: 0.5138\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 3.5502 - acc: 0.5798 - val_loss: 3.6735 - val_acc: 0.5251\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 3.4993 - acc: 0.5794 - val_loss: 3.6292 - val_acc: 0.5261\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 3.4423 - acc: 0.5839 - val_loss: 3.6052 - val_acc: 0.5195\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 3.3905 - acc: 0.5882 - val_loss: 3.5634 - val_acc: 0.5228\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 3.3393 - acc: 0.5921 - val_loss: 3.5137 - val_acc: 0.5227\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 3.2850 - acc: 0.5943 - val_loss: 3.4683 - val_acc: 0.5186\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 3.2383 - acc: 0.5966 - val_loss: 3.4837 - val_acc: 0.4990\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 3.1878 - acc: 0.5989 - val_loss: 3.3682 - val_acc: 0.5241\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 3.1433 - acc: 0.5994 - val_loss: 3.3372 - val_acc: 0.5279\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 3.0983 - acc: 0.6028 - val_loss: 3.3171 - val_acc: 0.5248\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 3.0488 - acc: 0.6063 - val_loss: 3.2511 - val_acc: 0.5261\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 2.9988 - acc: 0.6108 - val_loss: 3.2425 - val_acc: 0.5191\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 2.9566 - acc: 0.6139 - val_loss: 3.2180 - val_acc: 0.5197\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 2.9161 - acc: 0.6139 - val_loss: 3.1174 - val_acc: 0.5339\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 2.8747 - acc: 0.6153 - val_loss: 3.2415 - val_acc: 0.4913\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 2.8339 - acc: 0.6183 - val_loss: 3.0630 - val_acc: 0.5304\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 2.7895 - acc: 0.6220 - val_loss: 3.0163 - val_acc: 0.5326\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 2.7542 - acc: 0.6189 - val_loss: 3.0331 - val_acc: 0.5215\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 2.7144 - acc: 0.6228 - val_loss: 3.1635 - val_acc: 0.4810\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 2.6770 - acc: 0.6234 - val_loss: 2.9531 - val_acc: 0.5249\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 2.6355 - acc: 0.6280 - val_loss: 2.8968 - val_acc: 0.5288\n",
      "Experiment with Regulizer = ratio_ratio, regular_regular\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 3s 65us/step - loss: 2.1814 - acc: 0.2715 - val_loss: 2.0220 - val_acc: 0.3364\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 2s 50us/step - loss: 1.9506 - acc: 0.3662 - val_loss: 1.8974 - val_acc: 0.3855\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.8593 - acc: 0.3991 - val_loss: 1.8377 - val_acc: 0.4071\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 2s 50us/step - loss: 1.8004 - acc: 0.4191 - val_loss: 1.7849 - val_acc: 0.4288\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.7544 - acc: 0.4343 - val_loss: 1.7341 - val_acc: 0.4403\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.7132 - acc: 0.4492 - val_loss: 1.6982 - val_acc: 0.4545\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.6779 - acc: 0.4621 - val_loss: 1.6749 - val_acc: 0.4628\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.6488 - acc: 0.4705 - val_loss: 1.6536 - val_acc: 0.4651\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.6211 - acc: 0.4806 - val_loss: 1.6393 - val_acc: 0.4724\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.5946 - acc: 0.4891 - val_loss: 1.6237 - val_acc: 0.4719\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.5724 - acc: 0.4961 - val_loss: 1.6102 - val_acc: 0.4777\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.5491 - acc: 0.5049 - val_loss: 1.5939 - val_acc: 0.4827\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.5288 - acc: 0.5132 - val_loss: 1.5751 - val_acc: 0.4892\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.5088 - acc: 0.5186 - val_loss: 1.5772 - val_acc: 0.4862\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.4909 - acc: 0.5265 - val_loss: 1.5504 - val_acc: 0.4990\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.4705 - acc: 0.5301 - val_loss: 1.5481 - val_acc: 0.4994\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.4536 - acc: 0.5387 - val_loss: 1.5276 - val_acc: 0.5045\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.4346 - acc: 0.5459 - val_loss: 1.5420 - val_acc: 0.5025\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.4187 - acc: 0.5492 - val_loss: 1.5236 - val_acc: 0.5073\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.4018 - acc: 0.5572 - val_loss: 1.5608 - val_acc: 0.5023\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.3871 - acc: 0.5628 - val_loss: 1.5115 - val_acc: 0.5085\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.3707 - acc: 0.5660 - val_loss: 1.5585 - val_acc: 0.4966\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.3564 - acc: 0.5704 - val_loss: 1.4982 - val_acc: 0.5152\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.3395 - acc: 0.5780 - val_loss: 1.5067 - val_acc: 0.5180\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.3260 - acc: 0.5839 - val_loss: 1.5081 - val_acc: 0.5151\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.3122 - acc: 0.5863 - val_loss: 1.5273 - val_acc: 0.5112\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.2980 - acc: 0.5926 - val_loss: 1.5213 - val_acc: 0.5142\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.2846 - acc: 0.5959 - val_loss: 1.5074 - val_acc: 0.5154\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.2733 - acc: 0.6009 - val_loss: 1.5030 - val_acc: 0.5231\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.2573 - acc: 0.6069 - val_loss: 1.4824 - val_acc: 0.5266\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.2421 - acc: 0.6104 - val_loss: 1.5585 - val_acc: 0.5051\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.2318 - acc: 0.6149 - val_loss: 1.4851 - val_acc: 0.5218\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.2168 - acc: 0.6197 - val_loss: 1.5128 - val_acc: 0.5163\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.2053 - acc: 0.6251 - val_loss: 1.4942 - val_acc: 0.5256\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.1901 - acc: 0.6316 - val_loss: 1.4728 - val_acc: 0.5316\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.1752 - acc: 0.6340 - val_loss: 1.5124 - val_acc: 0.5244\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.1692 - acc: 0.6393 - val_loss: 1.4925 - val_acc: 0.5300\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.1547 - acc: 0.6441 - val_loss: 1.6345 - val_acc: 0.4873\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.1407 - acc: 0.6489 - val_loss: 1.5334 - val_acc: 0.5192\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.1317 - acc: 0.6533 - val_loss: 1.4875 - val_acc: 0.5374\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.1199 - acc: 0.6566 - val_loss: 1.5199 - val_acc: 0.5281\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.1060 - acc: 0.6595 - val_loss: 1.5331 - val_acc: 0.5257\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.0905 - acc: 0.6670 - val_loss: 1.4930 - val_acc: 0.5304\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.0792 - acc: 0.6699 - val_loss: 1.5681 - val_acc: 0.5204\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.0686 - acc: 0.6744 - val_loss: 1.5303 - val_acc: 0.5226\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.0571 - acc: 0.6796 - val_loss: 1.4902 - val_acc: 0.5368\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.0506 - acc: 0.6795 - val_loss: 1.7149 - val_acc: 0.4881\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.0334 - acc: 0.6874 - val_loss: 1.5715 - val_acc: 0.5179\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.0252 - acc: 0.6915 - val_loss: 1.5233 - val_acc: 0.5335\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.0089 - acc: 0.6952 - val_loss: 1.6154 - val_acc: 0.5125\n",
      "Experiment with Regulizer = ratio_ratio, regular_regular\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 3s 70us/step - loss: 18.8008 - acc: 0.2771 - val_loss: 17.3739 - val_acc: 0.3387\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 3s 51us/step - loss: 16.1509 - acc: 0.3559 - val_loss: 14.9911 - val_acc: 0.3610\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 13.9634 - acc: 0.3784 - val_loss: 12.9835 - val_acc: 0.3848\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 12.1136 - acc: 0.3908 - val_loss: 11.2847 - val_acc: 0.3975\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 10.5420 - acc: 0.4015 - val_loss: 9.8310 - val_acc: 0.4075\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 9.2049 - acc: 0.4093 - val_loss: 8.6064 - val_acc: 0.4133\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 8.0665 - acc: 0.4145 - val_loss: 7.5549 - val_acc: 0.4176\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 7.0967 - acc: 0.4176 - val_loss: 6.6577 - val_acc: 0.4202\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 6.2691 - acc: 0.4224 - val_loss: 5.8969 - val_acc: 0.4287\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 5.5662 - acc: 0.4270 - val_loss: 5.2534 - val_acc: 0.4257\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 4.9668 - acc: 0.4294 - val_loss: 4.7034 - val_acc: 0.4328\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 4.4579 - acc: 0.4323 - val_loss: 4.2310 - val_acc: 0.4366\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 4.0246 - acc: 0.4342 - val_loss: 3.8572 - val_acc: 0.4299\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 3.6566 - acc: 0.4382 - val_loss: 3.4978 - val_acc: 0.4362\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 3.3461 - acc: 0.4424 - val_loss: 3.2203 - val_acc: 0.4317\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 3.0824 - acc: 0.4442 - val_loss: 2.9737 - val_acc: 0.4372\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 2.8618 - acc: 0.4445 - val_loss: 2.7662 - val_acc: 0.4404\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 2.6766 - acc: 0.4459 - val_loss: 2.5979 - val_acc: 0.4388\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 2.5212 - acc: 0.4479 - val_loss: 2.4584 - val_acc: 0.4445\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 2.3924 - acc: 0.4469 - val_loss: 2.3352 - val_acc: 0.4484\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 2.2869 - acc: 0.4485 - val_loss: 2.2772 - val_acc: 0.4337\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 2.2000 - acc: 0.4498 - val_loss: 2.1719 - val_acc: 0.4477\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 2.1284 - acc: 0.4509 - val_loss: 2.1101 - val_acc: 0.4430\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 2.0716 - acc: 0.4506 - val_loss: 2.0534 - val_acc: 0.4443\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 2.0254 - acc: 0.4517 - val_loss: 2.0250 - val_acc: 0.4324\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.9873 - acc: 0.4519 - val_loss: 2.0252 - val_acc: 0.4334\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.9575 - acc: 0.4524 - val_loss: 2.0105 - val_acc: 0.4328\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.9325 - acc: 0.4532 - val_loss: 1.9254 - val_acc: 0.4560\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.9100 - acc: 0.4545 - val_loss: 1.9017 - val_acc: 0.4554\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.8913 - acc: 0.4576 - val_loss: 1.8936 - val_acc: 0.4483\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.8778 - acc: 0.4581 - val_loss: 1.9008 - val_acc: 0.4444\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.8648 - acc: 0.4574 - val_loss: 1.8862 - val_acc: 0.4399\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.8525 - acc: 0.4601 - val_loss: 1.8741 - val_acc: 0.4524\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.8423 - acc: 0.4611 - val_loss: 1.9081 - val_acc: 0.4347\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.8320 - acc: 0.4622 - val_loss: 1.8400 - val_acc: 0.4608\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.8239 - acc: 0.4631 - val_loss: 1.8376 - val_acc: 0.4555\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.8148 - acc: 0.4640 - val_loss: 1.8855 - val_acc: 0.4449\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.8079 - acc: 0.4651 - val_loss: 1.8361 - val_acc: 0.4550\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.7995 - acc: 0.4692 - val_loss: 1.8196 - val_acc: 0.4634\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.7958 - acc: 0.4690 - val_loss: 1.8118 - val_acc: 0.4692\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.7911 - acc: 0.4694 - val_loss: 1.8021 - val_acc: 0.4680\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.7840 - acc: 0.4721 - val_loss: 1.8101 - val_acc: 0.4598\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.7800 - acc: 0.4733 - val_loss: 1.7910 - val_acc: 0.4681\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.7767 - acc: 0.4723 - val_loss: 1.7796 - val_acc: 0.4721\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.7707 - acc: 0.4733 - val_loss: 1.8161 - val_acc: 0.4658\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.7665 - acc: 0.4747 - val_loss: 1.7982 - val_acc: 0.4502\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.7642 - acc: 0.4747 - val_loss: 1.7709 - val_acc: 0.4704\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.7581 - acc: 0.4761 - val_loss: 1.7737 - val_acc: 0.4709\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.7555 - acc: 0.4766 - val_loss: 1.7772 - val_acc: 0.4631\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.7521 - acc: 0.4772 - val_loss: 1.7789 - val_acc: 0.4658\n",
      "Experiment with Regulizer = ratio_ratio, regular_regular\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 3s 65us/step - loss: 2.0110 - acc: 0.2819 - val_loss: 1.8645 - val_acc: 0.3470\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.8055 - acc: 0.3698 - val_loss: 1.7548 - val_acc: 0.3854\n",
      "Epoch 3/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.7169 - acc: 0.3988 - val_loss: 1.6769 - val_acc: 0.4143\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.6536 - acc: 0.4232 - val_loss: 1.6266 - val_acc: 0.4282\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.6039 - acc: 0.4384 - val_loss: 1.6085 - val_acc: 0.4322\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 2s 50us/step - loss: 1.5649 - acc: 0.4521 - val_loss: 1.5655 - val_acc: 0.4485\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 2s 50us/step - loss: 1.5305 - acc: 0.4628 - val_loss: 1.5425 - val_acc: 0.4547\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.5007 - acc: 0.4720 - val_loss: 1.5119 - val_acc: 0.4679\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.4743 - acc: 0.4800 - val_loss: 1.4872 - val_acc: 0.4752\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.4478 - acc: 0.4904 - val_loss: 1.4744 - val_acc: 0.4791\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.4228 - acc: 0.5005 - val_loss: 1.4661 - val_acc: 0.4787\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.4019 - acc: 0.5065 - val_loss: 1.4405 - val_acc: 0.4922\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 2s 50us/step - loss: 1.3801 - acc: 0.5139 - val_loss: 1.4263 - val_acc: 0.4937\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.3598 - acc: 0.5214 - val_loss: 1.4115 - val_acc: 0.4997\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.3407 - acc: 0.5282 - val_loss: 1.4120 - val_acc: 0.4993\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.3207 - acc: 0.5361 - val_loss: 1.4026 - val_acc: 0.5069\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 2s 50us/step - loss: 1.3035 - acc: 0.5418 - val_loss: 1.3877 - val_acc: 0.5096\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.2886 - acc: 0.5473 - val_loss: 1.3952 - val_acc: 0.5085\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.2720 - acc: 0.5537 - val_loss: 1.3705 - val_acc: 0.5147\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.2532 - acc: 0.5586 - val_loss: 1.3761 - val_acc: 0.5138\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.2393 - acc: 0.5647 - val_loss: 1.3569 - val_acc: 0.5203\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.2224 - acc: 0.5717 - val_loss: 1.4170 - val_acc: 0.5018\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.2074 - acc: 0.5746 - val_loss: 1.4518 - val_acc: 0.4933\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.1960 - acc: 0.5790 - val_loss: 1.3699 - val_acc: 0.5180\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.1791 - acc: 0.5851 - val_loss: 1.3637 - val_acc: 0.5219\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.1671 - acc: 0.5893 - val_loss: 1.4057 - val_acc: 0.5067\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.1529 - acc: 0.5952 - val_loss: 1.3463 - val_acc: 0.5277\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.1368 - acc: 0.6011 - val_loss: 1.3486 - val_acc: 0.5217\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.1253 - acc: 0.6039 - val_loss: 1.3767 - val_acc: 0.5145\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.1121 - acc: 0.6062 - val_loss: 1.3436 - val_acc: 0.5238\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 2s 50us/step - loss: 1.1003 - acc: 0.6125 - val_loss: 1.3409 - val_acc: 0.5314\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.0821 - acc: 0.6197 - val_loss: 1.4030 - val_acc: 0.5108\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.0710 - acc: 0.6258 - val_loss: 1.3611 - val_acc: 0.5241\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.0602 - acc: 0.6287 - val_loss: 1.3823 - val_acc: 0.5184\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.0456 - acc: 0.6306 - val_loss: 1.3467 - val_acc: 0.5306\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.0350 - acc: 0.6351 - val_loss: 1.3373 - val_acc: 0.5350\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.0193 - acc: 0.6428 - val_loss: 1.3985 - val_acc: 0.5181\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.0072 - acc: 0.6470 - val_loss: 1.3555 - val_acc: 0.5302\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 0.9930 - acc: 0.6522 - val_loss: 1.3747 - val_acc: 0.5266\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 0.9824 - acc: 0.6526 - val_loss: 1.4533 - val_acc: 0.5051\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 0.9747 - acc: 0.6563 - val_loss: 1.4746 - val_acc: 0.4998\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 0.9543 - acc: 0.6628 - val_loss: 1.4043 - val_acc: 0.5175\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 0.9453 - acc: 0.6667 - val_loss: 1.3603 - val_acc: 0.5331\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 0.9390 - acc: 0.6684 - val_loss: 1.3889 - val_acc: 0.5239\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 0.9217 - acc: 0.6761 - val_loss: 1.3895 - val_acc: 0.5265\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 0.9095 - acc: 0.6810 - val_loss: 1.4306 - val_acc: 0.5155\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 0.9008 - acc: 0.6849 - val_loss: 1.4768 - val_acc: 0.5112\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 0.8888 - acc: 0.6876 - val_loss: 1.4080 - val_acc: 0.5278\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 0.8693 - acc: 0.6949 - val_loss: 1.4136 - val_acc: 0.5281\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 0.8663 - acc: 0.6958 - val_loss: 1.5217 - val_acc: 0.5066\n",
      "Experiment with Regulizer = ratio_ratio, regular_regular\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 3s 65us/step - loss: 2.0204 - acc: 0.2787 - val_loss: 1.8564 - val_acc: 0.3478\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 2s 50us/step - loss: 1.8056 - acc: 0.3675 - val_loss: 1.7577 - val_acc: 0.3862\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 2s 50us/step - loss: 1.7253 - acc: 0.3934 - val_loss: 1.7032 - val_acc: 0.4032\n",
      "Epoch 4/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 2s 50us/step - loss: 1.6670 - acc: 0.4148 - val_loss: 1.6599 - val_acc: 0.4147\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.6194 - acc: 0.4316 - val_loss: 1.6028 - val_acc: 0.4422\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 1.5807 - acc: 0.4448 - val_loss: 1.5835 - val_acc: 0.4437\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 2s 50us/step - loss: 1.5461 - acc: 0.4573 - val_loss: 1.5547 - val_acc: 0.4553\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 1.5185 - acc: 0.4661 - val_loss: 1.5293 - val_acc: 0.4591\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 2s 50us/step - loss: 1.4912 - acc: 0.4769 - val_loss: 1.5046 - val_acc: 0.4691\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 2s 50us/step - loss: 1.4638 - acc: 0.4859 - val_loss: 1.4846 - val_acc: 0.4746\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 2s 50us/step - loss: 1.4399 - acc: 0.4934 - val_loss: 1.4777 - val_acc: 0.4733\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.4173 - acc: 0.5026 - val_loss: 1.4538 - val_acc: 0.4844\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.3962 - acc: 0.5086 - val_loss: 1.4508 - val_acc: 0.4861\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.3739 - acc: 0.5160 - val_loss: 1.4328 - val_acc: 0.4857\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 2s 50us/step - loss: 1.3543 - acc: 0.5228 - val_loss: 1.4363 - val_acc: 0.4839\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 2s 50us/step - loss: 1.3371 - acc: 0.5304 - val_loss: 1.4082 - val_acc: 0.4948\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.3196 - acc: 0.5355 - val_loss: 1.3946 - val_acc: 0.5078\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.3002 - acc: 0.5425 - val_loss: 1.3959 - val_acc: 0.5048\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 2s 50us/step - loss: 1.2837 - acc: 0.5473 - val_loss: 1.3698 - val_acc: 0.5130\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 2s 50us/step - loss: 1.2676 - acc: 0.5542 - val_loss: 1.3813 - val_acc: 0.5042\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 2s 50us/step - loss: 1.2526 - acc: 0.5579 - val_loss: 1.3656 - val_acc: 0.5140\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 2s 50us/step - loss: 1.2376 - acc: 0.5638 - val_loss: 1.3861 - val_acc: 0.5102\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.2203 - acc: 0.5712 - val_loss: 1.3631 - val_acc: 0.5172\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.2072 - acc: 0.5763 - val_loss: 1.3754 - val_acc: 0.5114\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 2s 50us/step - loss: 1.1903 - acc: 0.5822 - val_loss: 1.3891 - val_acc: 0.5090\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 2s 50us/step - loss: 1.1760 - acc: 0.5862 - val_loss: 1.4043 - val_acc: 0.5068\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 2s 50us/step - loss: 1.1684 - acc: 0.5883 - val_loss: 1.3944 - val_acc: 0.5114\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.1502 - acc: 0.5956 - val_loss: 1.3549 - val_acc: 0.5159\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.1391 - acc: 0.5985 - val_loss: 1.3743 - val_acc: 0.5172\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 2s 50us/step - loss: 1.1231 - acc: 0.6024 - val_loss: 1.3626 - val_acc: 0.5222\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 2s 50us/step - loss: 1.1091 - acc: 0.6098 - val_loss: 1.3789 - val_acc: 0.5138\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.0978 - acc: 0.6141 - val_loss: 1.3389 - val_acc: 0.5316\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.0836 - acc: 0.6197 - val_loss: 1.3273 - val_acc: 0.5325\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.0698 - acc: 0.6222 - val_loss: 1.4271 - val_acc: 0.5108\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.0585 - acc: 0.6272 - val_loss: 1.3836 - val_acc: 0.5212\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.0490 - acc: 0.6289 - val_loss: 1.3677 - val_acc: 0.5240\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.0372 - acc: 0.6367 - val_loss: 1.3455 - val_acc: 0.5341\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 2s 50us/step - loss: 1.0216 - acc: 0.6411 - val_loss: 1.4134 - val_acc: 0.5147\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.0123 - acc: 0.6443 - val_loss: 1.3678 - val_acc: 0.5268\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 0.9938 - acc: 0.6493 - val_loss: 1.3683 - val_acc: 0.5265\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 2s 50us/step - loss: 0.9779 - acc: 0.6562 - val_loss: 1.3989 - val_acc: 0.5162\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 0.9697 - acc: 0.6594 - val_loss: 1.3566 - val_acc: 0.5290\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 0.9564 - acc: 0.6635 - val_loss: 1.4483 - val_acc: 0.5120\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 0.9501 - acc: 0.6679 - val_loss: 1.3944 - val_acc: 0.5259\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 0.9343 - acc: 0.6722 - val_loss: 1.3506 - val_acc: 0.5371\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 2s 50us/step - loss: 0.9171 - acc: 0.6780 - val_loss: 1.4963 - val_acc: 0.4963\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 0.9081 - acc: 0.6801 - val_loss: 1.4460 - val_acc: 0.5187\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 2s 50us/step - loss: 0.8989 - acc: 0.6850 - val_loss: 1.4473 - val_acc: 0.5093\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 2s 50us/step - loss: 0.8843 - acc: 0.6906 - val_loss: 1.4666 - val_acc: 0.5132\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 2s 50us/step - loss: 0.8724 - acc: 0.6928 - val_loss: 1.3905 - val_acc: 0.5307\n",
      "Experiment with Regulizer = ratio_ratio, regular_regular\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 3s 69us/step - loss: 15.0964 - acc: 0.2745 - val_loss: 13.9555 - val_acc: 0.3405\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 13.0212 - acc: 0.3600 - val_loss: 12.1259 - val_acc: 0.3780\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 11.3471 - acc: 0.3829 - val_loss: 10.6107 - val_acc: 0.3817\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 9.9335 - acc: 0.3975 - val_loss: 9.2955 - val_acc: 0.4017\n",
      "Epoch 5/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 3s 50us/step - loss: 8.7332 - acc: 0.4084 - val_loss: 8.1926 - val_acc: 0.4046\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 7.7100 - acc: 0.4158 - val_loss: 7.2495 - val_acc: 0.4196\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 6.8368 - acc: 0.4240 - val_loss: 6.4485 - val_acc: 0.4222\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 6.0932 - acc: 0.4286 - val_loss: 5.7576 - val_acc: 0.4308\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 5.4577 - acc: 0.4337 - val_loss: 5.1744 - val_acc: 0.4322\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 4.9147 - acc: 0.4387 - val_loss: 4.6721 - val_acc: 0.4391\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 4.4483 - acc: 0.4419 - val_loss: 4.2486 - val_acc: 0.4325\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 4.0512 - acc: 0.4469 - val_loss: 3.8810 - val_acc: 0.4396\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 3.7103 - acc: 0.4517 - val_loss: 3.5689 - val_acc: 0.4443\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 3.4198 - acc: 0.4544 - val_loss: 3.3090 - val_acc: 0.4456\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 3.1683 - acc: 0.4595 - val_loss: 3.0891 - val_acc: 0.4464\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 2.9544 - acc: 0.4596 - val_loss: 2.8769 - val_acc: 0.4488\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 2.7709 - acc: 0.4639 - val_loss: 2.7048 - val_acc: 0.4494\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 2.6129 - acc: 0.4691 - val_loss: 2.5783 - val_acc: 0.4452\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 2.4773 - acc: 0.4708 - val_loss: 2.4330 - val_acc: 0.4607\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 2.3601 - acc: 0.4748 - val_loss: 2.3386 - val_acc: 0.4649\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 2.2631 - acc: 0.4765 - val_loss: 2.2350 - val_acc: 0.4734\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 2.1756 - acc: 0.4797 - val_loss: 2.1528 - val_acc: 0.4745\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 2.1018 - acc: 0.4813 - val_loss: 2.1014 - val_acc: 0.4635\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 2.0362 - acc: 0.4855 - val_loss: 2.0433 - val_acc: 0.4676\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.9821 - acc: 0.4859 - val_loss: 1.9772 - val_acc: 0.4788\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.9340 - acc: 0.4864 - val_loss: 1.9702 - val_acc: 0.4623\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.8933 - acc: 0.4898 - val_loss: 1.9145 - val_acc: 0.4747\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.8598 - acc: 0.4933 - val_loss: 1.9000 - val_acc: 0.4694\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.8272 - acc: 0.4947 - val_loss: 1.8450 - val_acc: 0.4747\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.7992 - acc: 0.4961 - val_loss: 1.8335 - val_acc: 0.4786\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.7756 - acc: 0.4986 - val_loss: 1.8139 - val_acc: 0.4742\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.7556 - acc: 0.5002 - val_loss: 1.7779 - val_acc: 0.4875\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.7380 - acc: 0.5005 - val_loss: 1.7654 - val_acc: 0.4888\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.7226 - acc: 0.5008 - val_loss: 1.8463 - val_acc: 0.4419\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.7099 - acc: 0.5057 - val_loss: 1.7472 - val_acc: 0.4914\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.6949 - acc: 0.5059 - val_loss: 1.7546 - val_acc: 0.4807\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.6865 - acc: 0.5069 - val_loss: 1.7440 - val_acc: 0.4746\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.6756 - acc: 0.5087 - val_loss: 1.7058 - val_acc: 0.5003\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.6664 - acc: 0.5112 - val_loss: 1.7206 - val_acc: 0.4842\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.6600 - acc: 0.5129 - val_loss: 1.7083 - val_acc: 0.4926\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.6527 - acc: 0.5140 - val_loss: 1.7131 - val_acc: 0.4882\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.6460 - acc: 0.5142 - val_loss: 1.6924 - val_acc: 0.4967\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.6392 - acc: 0.5174 - val_loss: 1.6976 - val_acc: 0.4974\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.6345 - acc: 0.5174 - val_loss: 1.6740 - val_acc: 0.5049\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.6285 - acc: 0.5191 - val_loss: 1.7265 - val_acc: 0.4700\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.6261 - acc: 0.5198 - val_loss: 1.6695 - val_acc: 0.4996\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.6218 - acc: 0.5228 - val_loss: 1.6720 - val_acc: 0.4962\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.6182 - acc: 0.5213 - val_loss: 1.6771 - val_acc: 0.4983\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.6138 - acc: 0.5241 - val_loss: 1.7042 - val_acc: 0.4945\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.6109 - acc: 0.5238 - val_loss: 1.7265 - val_acc: 0.4630\n",
      "Experiment with Regulizer = ratio_ratio, regular_regular\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 3s 66us/step - loss: 2.0360 - acc: 0.2728 - val_loss: 1.8665 - val_acc: 0.3468\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.8091 - acc: 0.3654 - val_loss: 1.7542 - val_acc: 0.3864\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.7243 - acc: 0.3972 - val_loss: 1.6913 - val_acc: 0.4059\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.6670 - acc: 0.4173 - val_loss: 1.6433 - val_acc: 0.4277\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.6193 - acc: 0.4333 - val_loss: 1.6047 - val_acc: 0.4367\n",
      "Epoch 6/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.5783 - acc: 0.4495 - val_loss: 1.5821 - val_acc: 0.4407\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.5459 - acc: 0.4596 - val_loss: 1.5539 - val_acc: 0.4560\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.5140 - acc: 0.4716 - val_loss: 1.5221 - val_acc: 0.4686\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.4859 - acc: 0.4779 - val_loss: 1.4993 - val_acc: 0.4698\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.4596 - acc: 0.4887 - val_loss: 1.4880 - val_acc: 0.4762\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.4365 - acc: 0.4957 - val_loss: 1.4893 - val_acc: 0.4697\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.4128 - acc: 0.5051 - val_loss: 1.4783 - val_acc: 0.47341s - loss: 1.4150 - acc: - ETA: 1s - \n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.3923 - acc: 0.5118 - val_loss: 1.4339 - val_acc: 0.4924\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.3730 - acc: 0.5185 - val_loss: 1.4365 - val_acc: 0.4879\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.3537 - acc: 0.5270 - val_loss: 1.4420 - val_acc: 0.48443546 - acc:\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.3351 - acc: 0.5320 - val_loss: 1.4156 - val_acc: 0.49943337 - acc: 0.5\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.3165 - acc: 0.5407 - val_loss: 1.4244 - val_acc: 0.4957\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.3007 - acc: 0.5430 - val_loss: 1.3930 - val_acc: 0.5047\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.2835 - acc: 0.5493 - val_loss: 1.3835 - val_acc: 0.5019\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.2686 - acc: 0.5539 - val_loss: 1.3875 - val_acc: 0.5001\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.2518 - acc: 0.5601 - val_loss: 1.3709 - val_acc: 0.5144\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.2350 - acc: 0.5667 - val_loss: 1.3918 - val_acc: 0.5038\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.2195 - acc: 0.5708 - val_loss: 1.3885 - val_acc: 0.4997\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.2079 - acc: 0.5755 - val_loss: 1.3535 - val_acc: 0.5198\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.1924 - acc: 0.5815 - val_loss: 1.3764 - val_acc: 0.5078\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.1763 - acc: 0.5866 - val_loss: 1.3825 - val_acc: 0.5098\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.1637 - acc: 0.5898 - val_loss: 1.3520 - val_acc: 0.5181\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.1474 - acc: 0.5964 - val_loss: 1.3480 - val_acc: 0.5211\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.1370 - acc: 0.6003 - val_loss: 1.3509 - val_acc: 0.5212\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.1240 - acc: 0.6055 - val_loss: 1.3952 - val_acc: 0.5159\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.1087 - acc: 0.6099 - val_loss: 1.3762 - val_acc: 0.5219\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.0935 - acc: 0.6162 - val_loss: 1.4592 - val_acc: 0.4978\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.0838 - acc: 0.6196 - val_loss: 1.4057 - val_acc: 0.5112\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.0689 - acc: 0.6264 - val_loss: 1.3406 - val_acc: 0.5285\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.0561 - acc: 0.6297 - val_loss: 1.3316 - val_acc: 0.5316\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.0478 - acc: 0.6296 - val_loss: 1.3707 - val_acc: 0.5242\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.0308 - acc: 0.6376 - val_loss: 1.3497 - val_acc: 0.5280\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.0219 - acc: 0.6404 - val_loss: 1.4861 - val_acc: 0.4995\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.0080 - acc: 0.6452 - val_loss: 1.4648 - val_acc: 0.5072\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 0.9928 - acc: 0.6501 - val_loss: 1.4164 - val_acc: 0.5145\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 0.9828 - acc: 0.6545 - val_loss: 1.3559 - val_acc: 0.5260\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 0.9692 - acc: 0.6596 - val_loss: 1.4562 - val_acc: 0.5067\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 0.9569 - acc: 0.6638 - val_loss: 1.4097 - val_acc: 0.5176\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 0.9417 - acc: 0.6684 - val_loss: 1.4094 - val_acc: 0.5208\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 0.9401 - acc: 0.6687 - val_loss: 1.4196 - val_acc: 0.5182\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 0.9206 - acc: 0.6767 - val_loss: 1.3598 - val_acc: 0.5350\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 0.9111 - acc: 0.6803 - val_loss: 1.4146 - val_acc: 0.5235\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 0.8984 - acc: 0.6834 - val_loss: 1.4180 - val_acc: 0.5230\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 0.8859 - acc: 0.6872 - val_loss: 1.3715 - val_acc: 0.5301\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 0.8762 - acc: 0.6931 - val_loss: 1.3470 - val_acc: 0.5411\n",
      "Experiment with Regulizer = ratio_ratio, regular_regular\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 3s 66us/step - loss: 2.0258 - acc: 0.2752 - val_loss: 1.8570 - val_acc: 0.3526\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.8008 - acc: 0.3696 - val_loss: 1.7571 - val_acc: 0.3803\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.7199 - acc: 0.3982 - val_loss: 1.6887 - val_acc: 0.4102\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.6630 - acc: 0.4180 - val_loss: 1.6460 - val_acc: 0.4237\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.6158 - acc: 0.4334 - val_loss: 1.6160 - val_acc: 0.4295\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.5781 - acc: 0.4476 - val_loss: 1.5781 - val_acc: 0.4422\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.5436 - acc: 0.4577 - val_loss: 1.5447 - val_acc: 0.4579\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.5143 - acc: 0.4692 - val_loss: 1.5235 - val_acc: 0.4613\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.4875 - acc: 0.4792 - val_loss: 1.5062 - val_acc: 0.4718\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.4609 - acc: 0.4866 - val_loss: 1.4872 - val_acc: 0.4753\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.4372 - acc: 0.4949 - val_loss: 1.4748 - val_acc: 0.4811\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.4148 - acc: 0.5014 - val_loss: 1.4717 - val_acc: 0.4768\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.3923 - acc: 0.5106 - val_loss: 1.4450 - val_acc: 0.4883\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.3723 - acc: 0.5162 - val_loss: 1.4354 - val_acc: 0.4932\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.3526 - acc: 0.5238 - val_loss: 1.4642 - val_acc: 0.4775\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.3341 - acc: 0.5301 - val_loss: 1.4087 - val_acc: 0.5034\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.3162 - acc: 0.5371 - val_loss: 1.4376 - val_acc: 0.4898\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.3010 - acc: 0.5414 - val_loss: 1.3913 - val_acc: 0.5107\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.2823 - acc: 0.5490 - val_loss: 1.3929 - val_acc: 0.5088\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.2661 - acc: 0.5548 - val_loss: 1.3865 - val_acc: 0.5085\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 2s 50us/step - loss: 1.2512 - acc: 0.5603 - val_loss: 1.3749 - val_acc: 0.5143\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 2s 50us/step - loss: 1.2345 - acc: 0.5661 - val_loss: 1.3875 - val_acc: 0.5109\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 1.2233 - acc: 0.5688 - val_loss: 1.3569 - val_acc: 0.5181\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.2062 - acc: 0.5737 - val_loss: 1.3691 - val_acc: 0.5186\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 2s 50us/step - loss: 1.1931 - acc: 0.5810 - val_loss: 1.3611 - val_acc: 0.5199\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 2s 50us/step - loss: 1.1799 - acc: 0.5841 - val_loss: 1.3940 - val_acc: 0.5062\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 2s 50us/step - loss: 1.1672 - acc: 0.5901 - val_loss: 1.3493 - val_acc: 0.5237\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 2s 50us/step - loss: 1.1535 - acc: 0.5928 - val_loss: 1.3461 - val_acc: 0.5273\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 2s 50us/step - loss: 1.1402 - acc: 0.6001 - val_loss: 1.4162 - val_acc: 0.5009\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 2s 50us/step - loss: 1.1294 - acc: 0.6017 - val_loss: 1.3360 - val_acc: 0.5269\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.1136 - acc: 0.6065 - val_loss: 1.3627 - val_acc: 0.5186\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.0990 - acc: 0.6137 - val_loss: 1.4000 - val_acc: 0.5120\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 2s 50us/step - loss: 1.0895 - acc: 0.6172 - val_loss: 1.3525 - val_acc: 0.5246\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 2s 50us/step - loss: 1.0772 - acc: 0.6230 - val_loss: 1.3929 - val_acc: 0.5127\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 2s 50us/step - loss: 1.0617 - acc: 0.6267 - val_loss: 1.3459 - val_acc: 0.5285\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.0476 - acc: 0.6311 - val_loss: 1.3331 - val_acc: 0.5348\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.0378 - acc: 0.6374 - val_loss: 1.3518 - val_acc: 0.5268\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.0248 - acc: 0.6406 - val_loss: 1.3855 - val_acc: 0.5264\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.0120 - acc: 0.6450 - val_loss: 1.3627 - val_acc: 0.5276\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.0032 - acc: 0.6486 - val_loss: 1.3780 - val_acc: 0.5217\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 0.9869 - acc: 0.6542 - val_loss: 1.3865 - val_acc: 0.5187\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 0.9760 - acc: 0.6580 - val_loss: 1.3712 - val_acc: 0.5205\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 0.9619 - acc: 0.6611 - val_loss: 1.3704 - val_acc: 0.5235\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 0.9554 - acc: 0.6641 - val_loss: 1.4857 - val_acc: 0.5003\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 0.9407 - acc: 0.6704 - val_loss: 1.3868 - val_acc: 0.5235\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 0.9301 - acc: 0.6736 - val_loss: 1.3721 - val_acc: 0.5235\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 0.9165 - acc: 0.6787 - val_loss: 1.4203 - val_acc: 0.5202\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 0.9090 - acc: 0.6817 - val_loss: 1.4403 - val_acc: 0.5155\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 0.8890 - acc: 0.6894 - val_loss: 1.4065 - val_acc: 0.5207\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 0.8821 - acc: 0.6918 - val_loss: 1.6380 - val_acc: 0.4841\n",
      "Experiment with Regulizer = ratio_ratio, regular_regular\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 3s 69us/step - loss: 15.0890 - acc: 0.2694 - val_loss: 13.9501 - val_acc: 0.3330\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 13.0134 - acc: 0.3590 - val_loss: 12.1262 - val_acc: 0.3707\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 2s 50us/step - loss: 11.3405 - acc: 0.3861 - val_loss: 10.5878 - val_acc: 0.3883\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 9.9276 - acc: 0.3989 - val_loss: 9.2874 - val_acc: 0.4053\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 8.7282 - acc: 0.4087 - val_loss: 8.1862 - val_acc: 0.4153\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 7.7056 - acc: 0.4164 - val_loss: 7.2432 - val_acc: 0.4186\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 6.8335 - acc: 0.4235 - val_loss: 6.4392 - val_acc: 0.4225\n",
      "Epoch 8/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 2s 50us/step - loss: 6.0891 - acc: 0.4298 - val_loss: 5.7638 - val_acc: 0.4326\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 5.4542 - acc: 0.4345 - val_loss: 5.1703 - val_acc: 0.4328\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 4.9103 - acc: 0.4405 - val_loss: 4.6662 - val_acc: 0.4407\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 2s 50us/step - loss: 4.4469 - acc: 0.4439 - val_loss: 4.2495 - val_acc: 0.4380\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 4.0494 - acc: 0.4476 - val_loss: 3.8835 - val_acc: 0.4410\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 3.7089 - acc: 0.4512 - val_loss: 3.5633 - val_acc: 0.4495\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 3.4168 - acc: 0.4554 - val_loss: 3.2969 - val_acc: 0.4548\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 3.1677 - acc: 0.4581 - val_loss: 3.0653 - val_acc: 0.4567\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 2.9530 - acc: 0.4607 - val_loss: 2.8860 - val_acc: 0.4481\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 2.7696 - acc: 0.4658 - val_loss: 2.7006 - val_acc: 0.4607\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 2.6122 - acc: 0.4666 - val_loss: 2.5763 - val_acc: 0.4538\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 2.4788 - acc: 0.4685 - val_loss: 2.4283 - val_acc: 0.4697\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 2.3606 - acc: 0.4733 - val_loss: 2.3442 - val_acc: 0.4589\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 2.2617 - acc: 0.4746 - val_loss: 2.2324 - val_acc: 0.4731\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 2.1759 - acc: 0.4786 - val_loss: 2.1702 - val_acc: 0.4699\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 2.1019 - acc: 0.4805 - val_loss: 2.0947 - val_acc: 0.4672\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 2.0372 - acc: 0.4825 - val_loss: 2.0327 - val_acc: 0.4737\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.9819 - acc: 0.4845 - val_loss: 1.9875 - val_acc: 0.4769\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.9338 - acc: 0.4865 - val_loss: 1.9495 - val_acc: 0.4758\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.8946 - acc: 0.4892 - val_loss: 1.9199 - val_acc: 0.4665\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.8573 - acc: 0.4908 - val_loss: 1.8678 - val_acc: 0.4809\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.8261 - acc: 0.4930 - val_loss: 1.8377 - val_acc: 0.4859\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.8001 - acc: 0.4956 - val_loss: 1.8141 - val_acc: 0.4916\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.7768 - acc: 0.4958 - val_loss: 1.8060 - val_acc: 0.4734\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.7542 - acc: 0.4992 - val_loss: 1.7843 - val_acc: 0.4835\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.7362 - acc: 0.5009 - val_loss: 1.7781 - val_acc: 0.4862\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.7233 - acc: 0.5013 - val_loss: 1.7604 - val_acc: 0.4813\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.7093 - acc: 0.5020 - val_loss: 1.7440 - val_acc: 0.4890\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.6973 - acc: 0.5052 - val_loss: 1.7773 - val_acc: 0.4678\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.6846 - acc: 0.5079 - val_loss: 1.7335 - val_acc: 0.4891\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.6753 - acc: 0.5085 - val_loss: 1.7211 - val_acc: 0.4867\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.6684 - acc: 0.5088 - val_loss: 1.7207 - val_acc: 0.4936\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.6580 - acc: 0.5141 - val_loss: 1.6892 - val_acc: 0.4995\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.6523 - acc: 0.5146 - val_loss: 1.7015 - val_acc: 0.4998\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.6464 - acc: 0.5137 - val_loss: 1.6939 - val_acc: 0.4978\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.6419 - acc: 0.5162 - val_loss: 1.6922 - val_acc: 0.4962\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.6345 - acc: 0.5174 - val_loss: 1.7010 - val_acc: 0.4875\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.6288 - acc: 0.5197 - val_loss: 1.6978 - val_acc: 0.4987\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.6258 - acc: 0.5203 - val_loss: 1.6685 - val_acc: 0.5033\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.6212 - acc: 0.5210 - val_loss: 1.6736 - val_acc: 0.5027\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.6171 - acc: 0.5243 - val_loss: 1.7325 - val_acc: 0.4727\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.6162 - acc: 0.5246 - val_loss: 1.6797 - val_acc: 0.4931\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.6128 - acc: 0.5234 - val_loss: 1.6824 - val_acc: 0.4944\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Set your training loop\n",
    "\"\"\"\n",
    "results = {}\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "for g in ParameterGrid(params):\n",
    "    keras.backend.clear_session() # 把舊的 Graph 清掉\n",
    "    print(\"Experiment with Regulizer = ratio_{}, regular_{}\".format(*g))\n",
    "    model = build_mlp(**g)\n",
    "    model.summary()\n",
    "    optimizer = keras.optimizers.SGD(lr=LEARNING_RATE, nesterov=True, momentum=MOMENTUM)\n",
    "    model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=optimizer)\n",
    "\n",
    "    model.fit(x_train, y_train, \n",
    "              epochs=EPOCHS, \n",
    "              batch_size=BATCH_SIZE, \n",
    "              validation_data=(x_test, y_test), \n",
    "              shuffle=True)\n",
    "    \n",
    "    # Collect results\n",
    "    train_loss = model.history.history[\"loss\"]\n",
    "    valid_loss = model.history.history[\"val_loss\"]\n",
    "    train_acc = model.history.history[\"acc\"]\n",
    "    valid_acc = model.history.history[\"val_acc\"]\n",
    "    \n",
    "    exp_name_tag = \"exp-{}-{}\".format(*g)\n",
    "    results[exp_name_tag] = {'train-loss': train_loss,\n",
    "                             'valid-loss': valid_loss,\n",
    "                             'train-acc': train_acc,\n",
    "                             'valid-acc': valid_acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "color_bar = [\"r\", \"g\", \"b\", \"y\", \"m\", \"k\"]\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "for i, cond in enumerate(results.keys()):\n",
    "    plt.plot(range(len(results[cond]['train-loss'])),results[cond]['train-loss'], '-', label=cond, color=color_bar[i])\n",
    "    plt.plot(range(len(results[cond]['valid-loss'])),results[cond]['valid-loss'], '--', label=cond, color=color_bar[i])\n",
    "plt.title(\"Loss\")\n",
    "plt.ylim([0, 5])\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "for i, cond in enumerate(results.keys()):\n",
    "    plt.plot(range(len(results[cond]['train-acc'])),results[cond]['train-acc'], '-', label=cond, color=color_bar[i])\n",
    "    plt.plot(range(len(results[cond]['valid-acc'])),results[cond]['valid-acc'], '--', label=cond, color=color_bar[i])\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
